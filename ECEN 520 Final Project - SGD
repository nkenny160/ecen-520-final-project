{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":4.669361,"end_time":"2024-10-10T13:05:46.686069","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-10T13:05:42.016708","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport polars as pl\n\nimport kaggle_evaluation.jane_street_inference_server\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import SGDRegressor, LinearRegression\n\n# Load dataset (assuming already combined from multiple parquet files)\ndf = pd.read_parquet('/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet')\ndf.describe()","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-26T01:13:17.828508Z","iopub.execute_input":"2024-11-26T01:13:17.829565Z","iopub.status.idle":"2024-11-26T01:13:32.406934Z","shell.execute_reply.started":"2024-11-26T01:13:17.829513Z","shell.execute_reply":"2024-11-26T01:13:32.405628Z"},"papermill":{"duration":1.223703,"end_time":"2024-10-10T13:05:45.825911","exception":false,"start_time":"2024-10-10T13:05:44.602208","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            date_id       time_id     symbol_id        weight  feature_00  \\\ncount  1.944210e+06  1.944210e+06  1.944210e+06  1.944210e+06         0.0   \nmean   9.384629e+01  4.240000e+02  1.376638e+01  1.973281e+00         NaN   \nstd    4.813196e+01  2.450851e+02  1.108778e+01  9.691969e-01         NaN   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  4.405696e-01         NaN   \n25%    5.400000e+01  2.120000e+02  7.000000e+00  1.323803e+00         NaN   \n50%    9.900000e+01  4.240000e+02  1.200000e+01  1.763827e+00         NaN   \n75%    1.360000e+02  6.360000e+02  1.700000e+01  2.393846e+00         NaN   \nmax    1.690000e+02  8.480000e+02  3.800000e+01  6.011999e+00         NaN   \n\n       feature_01  feature_02  feature_03  feature_04    feature_05  ...  \\\ncount         0.0         0.0         0.0         0.0  1.944210e+06  ...   \nmean          NaN         NaN         NaN         NaN -4.463175e-02  ...   \nstd           NaN         NaN         NaN         NaN  9.479579e-01  ...   \nmin           NaN         NaN         NaN         NaN -1.176608e+01  ...   \n25%           NaN         NaN         NaN         NaN -4.756072e-01  ...   \n50%           NaN         NaN         NaN         NaN -5.818180e-02  ...   \n75%           NaN         NaN         NaN         NaN  3.493771e-01  ...   \nmax           NaN         NaN         NaN         NaN  1.532000e+01  ...   \n\n         feature_78   responder_0   responder_1   responder_2   responder_3  \\\ncount  1.944210e+06  1.944210e+06  1.944210e+06  1.944210e+06  1.944210e+06   \nmean  -9.805073e-02  8.424639e-03  1.076465e-02  2.412764e-03  1.139089e-02   \nstd    6.398993e-01  9.558780e-01  1.141793e+00  8.442027e-01  1.276044e+00   \nmin   -3.393299e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00   \n25%   -3.195696e-01 -2.322211e-01 -2.667868e-01 -1.210319e-01 -4.444537e-01   \n50%   -2.468792e-01 -3.943805e-03 -2.333469e-02 -1.248489e-03 -1.031224e-02   \n75%   -1.256560e-01  2.309678e-01  2.538152e-01  1.191232e-01  4.292141e-01   \nmax    4.370195e+01  5.000000e+00  5.000000e+00  5.000000e+00  5.000000e+00   \n\n        responder_4   responder_5   responder_6   responder_7   responder_8  \ncount  1.944210e+06  1.944210e+06  1.944210e+06  1.944210e+06  1.944210e+06  \nmean   2.185480e-02  3.326982e-03  1.487634e-03 -4.817980e-04  1.078154e-03  \nstd    1.266448e+00  1.225165e+00  8.705768e-01  8.918150e-01  8.737320e-01  \nmin   -5.000000e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00 -5.000000e+00  \n25%   -5.146699e-01 -2.569897e-01 -3.558709e-01 -3.914038e-01 -2.892584e-01  \n50%   -1.836913e-02 -4.690550e-03 -9.597129e-03 -2.376243e-02 -3.107830e-04  \n75%    5.065366e-01  2.438874e-01  3.360999e-01  3.463979e-01  2.840819e-01  \nmax    5.000000e+00  5.000000e+00  5.000000e+00  5.000000e+00  5.000000e+00  \n\n[8 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_id</th>\n      <th>time_id</th>\n      <th>symbol_id</th>\n      <th>weight</th>\n      <th>feature_00</th>\n      <th>feature_01</th>\n      <th>feature_02</th>\n      <th>feature_03</th>\n      <th>feature_04</th>\n      <th>feature_05</th>\n      <th>...</th>\n      <th>feature_78</th>\n      <th>responder_0</th>\n      <th>responder_1</th>\n      <th>responder_2</th>\n      <th>responder_3</th>\n      <th>responder_4</th>\n      <th>responder_5</th>\n      <th>responder_6</th>\n      <th>responder_7</th>\n      <th>responder_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.944210e+06</td>\n      <td>...</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n      <td>1.944210e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.384629e+01</td>\n      <td>4.240000e+02</td>\n      <td>1.376638e+01</td>\n      <td>1.973281e+00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.463175e-02</td>\n      <td>...</td>\n      <td>-9.805073e-02</td>\n      <td>8.424639e-03</td>\n      <td>1.076465e-02</td>\n      <td>2.412764e-03</td>\n      <td>1.139089e-02</td>\n      <td>2.185480e-02</td>\n      <td>3.326982e-03</td>\n      <td>1.487634e-03</td>\n      <td>-4.817980e-04</td>\n      <td>1.078154e-03</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.813196e+01</td>\n      <td>2.450851e+02</td>\n      <td>1.108778e+01</td>\n      <td>9.691969e-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.479579e-01</td>\n      <td>...</td>\n      <td>6.398993e-01</td>\n      <td>9.558780e-01</td>\n      <td>1.141793e+00</td>\n      <td>8.442027e-01</td>\n      <td>1.276044e+00</td>\n      <td>1.266448e+00</td>\n      <td>1.225165e+00</td>\n      <td>8.705768e-01</td>\n      <td>8.918150e-01</td>\n      <td>8.737320e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>4.405696e-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.176608e+01</td>\n      <td>...</td>\n      <td>-3.393299e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n      <td>-5.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>5.400000e+01</td>\n      <td>2.120000e+02</td>\n      <td>7.000000e+00</td>\n      <td>1.323803e+00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.756072e-01</td>\n      <td>...</td>\n      <td>-3.195696e-01</td>\n      <td>-2.322211e-01</td>\n      <td>-2.667868e-01</td>\n      <td>-1.210319e-01</td>\n      <td>-4.444537e-01</td>\n      <td>-5.146699e-01</td>\n      <td>-2.569897e-01</td>\n      <td>-3.558709e-01</td>\n      <td>-3.914038e-01</td>\n      <td>-2.892584e-01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.900000e+01</td>\n      <td>4.240000e+02</td>\n      <td>1.200000e+01</td>\n      <td>1.763827e+00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-5.818180e-02</td>\n      <td>...</td>\n      <td>-2.468792e-01</td>\n      <td>-3.943805e-03</td>\n      <td>-2.333469e-02</td>\n      <td>-1.248489e-03</td>\n      <td>-1.031224e-02</td>\n      <td>-1.836913e-02</td>\n      <td>-4.690550e-03</td>\n      <td>-9.597129e-03</td>\n      <td>-2.376243e-02</td>\n      <td>-3.107830e-04</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.360000e+02</td>\n      <td>6.360000e+02</td>\n      <td>1.700000e+01</td>\n      <td>2.393846e+00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.493771e-01</td>\n      <td>...</td>\n      <td>-1.256560e-01</td>\n      <td>2.309678e-01</td>\n      <td>2.538152e-01</td>\n      <td>1.191232e-01</td>\n      <td>4.292141e-01</td>\n      <td>5.065366e-01</td>\n      <td>2.438874e-01</td>\n      <td>3.360999e-01</td>\n      <td>3.463979e-01</td>\n      <td>2.840819e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.690000e+02</td>\n      <td>8.480000e+02</td>\n      <td>3.800000e+01</td>\n      <td>6.011999e+00</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.532000e+01</td>\n      <td>...</td>\n      <td>4.370195e+01</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>5.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Target and features\ntarget = 'responder_6'\nfeatures = ['feature_05','feature_06','feature_07','feature_09','feature_10','feature_11','feature_12','feature_13','feature_14','feature_20','feature_22','feature_23','feature_24','feature_25','feature_28','feature_29','feature_30','feature_34','feature_35','feature_36','feature_38','feature_48','feature_49','feature_59','feature_60','feature_61','feature_67','feature_68','feature_69','feature_70','feature_71','feature_72']\n# features = [col for col in df.columns if col not in [target, 'date_id','time_id', 'weight', 'symbol_id', 'responder_0', 'responder_1','responder_2','responder_3','responder_4','responder_5','responder_7', 'responder_8', 'responder_9']]\nusable_features = df[[col for col in df.columns if col in features]]\n\nscaler = StandardScaler()\nusable_features_scaled = scaler.fit_transform(usable_features)\n\nencoded = pd.get_dummies(df['symbol_id'], prefix='symbol_id')\nencoded.head()\n\n# # Splitting data into train and test set\n\n# Define a split point\nsplit_index = int(len(df) * 0.8)\n\n# filtered_df = pd.concat([df[['date_id', 'time_id', 'weight']],pd.DataFrame(usable_features_scaled, columns=features), encoded], axis=1)\nfiltered_df = pd.concat([pd.DataFrame(usable_features_scaled, columns=features), encoded], axis=1)\n\n# Split data\ntrain_data = filtered_df.iloc[:split_index]\ntest_data = filtered_df.iloc[split_index:]\n\nresponder_train = df.iloc[:split_index]\nresponder_test = df.iloc[split_index:]\n\n# Extract features and target\n# X_train = train_data[['symbol_id', 'date_id', 'time_id', 'weight'] + features]\n# y_train = responder_train[target]\n\n# X_test = test_data[['symbol_id', 'date_id', 'time_id', 'weight'] + features]\n# y_test = responder_test[target]\n\nX_train = train_data\ny_train = responder_train[target]\n\nX_test = test_data\ny_test = responder_test[target]","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-26T01:27:54.967913Z","iopub.execute_input":"2024-11-26T01:27:54.968377Z","iopub.status.idle":"2024-11-26T01:27:56.252086Z","shell.execute_reply.started":"2024-11-26T01:27:54.968338Z","shell.execute_reply":"2024-11-26T01:27:56.250673Z"},"papermill":{"duration":1.223703,"end_time":"2024-10-10T13:05:45.825911","exception":false,"start_time":"2024-10-10T13:05:44.602208","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Training basic SGD and BGD models","metadata":{}},{"cell_type":"code","source":"\n# SGD and BGD pipelines\n# sgd_pipeline = Pipeline(steps=[\n#     ('regressor', SGDRegressor(max_iter=1000, tol=1e-3, random_state=42))\n# ])\n\n# bgd_pipeline = Pipeline(steps=[\n#     ('regressor', LinearRegression())\n# ])\n\n# Train models\n# sgd_pipeline.fit(X_train, y_train)\n# bgd_pipeline.fit(X_train, y_train)\n\nregr = LinearRegression() \nregr.fit(X_train, y_train)\n\naccuracy = regr.score(X_test, y_test)\nprint(f'Linear Regression Accuracy: {accuracy * 100:.2f}%')","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-26T01:45:46.238796Z","iopub.execute_input":"2024-11-26T01:45:46.239214Z","iopub.status.idle":"2024-11-26T01:45:49.141381Z","shell.execute_reply.started":"2024-11-26T01:45:46.239178Z","shell.execute_reply":"2024-11-26T01:45:49.129319Z"},"papermill":{"duration":1.223703,"end_time":"2024-10-10T13:05:45.825911","exception":false,"start_time":"2024-10-10T13:05:44.602208","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Linear Regression Accuracy: 1.51%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Attempting to refine SGD using GridSearchCV","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import SGDRegressor\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'alpha': [0.0001, 0.001, 0.01],  # L2 regularization strength\n    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n    'eta0': [0.01, 0.1, 1.0],  # Initial learning rate\n}\ngrid = GridSearchCV(SGDRegressor(max_iter=1000, tol=1e-3), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid.fit(X_train, y_train)\nprint(grid.best_params_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T01:46:50.385373Z","iopub.execute_input":"2024-11-26T01:46:50.385893Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:1548: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Support Vector Machine (SVM) model testing","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm_model = SVC(kernel='rbf')\nsvm_model.fit(X_train_scaled_Z, y_train)\nsvm_accuracy = svm_model.score(X_test_scaled_Z, y_test)\nprint(f'SVM Accuracy: {svm_accuracy * 100:.2f}%')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in `jane_street_gateway` will run in a different container with direct access to the hidden test set and hand off the data timestep by timestep.\n\n\n\nYour code will always have access to the published copies of the files.","metadata":{"papermill":{"duration":0.002051,"end_time":"2024-10-10T13:05:45.83073","exception":false,"start_time":"2024-10-10T13:05:45.828679","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\n\n\n# Replace this function with your inference code.\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each batch of predictions (except the very first) must be returned within 1 minute of the batch features being provided.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n    # Use them as extra features, if you like.\n    global lags_\n    if lags is not None:\n        lags_ = lags\n\n    # Replace this section with your own predictions\n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).alias('responder_6'),\n    )\n\n    if isinstance(predictions, pl.DataFrame):\n        assert predictions.columns == ['row_id', 'responder_6']\n    elif isinstance(predictions, pd.DataFrame):\n        assert (predictions.columns == ['row_id', 'responder_6']).all()\n    else:\n        raise TypeError('The predict function must return a DataFrame')\n    # Confirm has as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-10T13:05:45.837368Z","iopub.status.busy":"2024-10-10T13:05:45.836455Z","iopub.status.idle":"2024-10-10T13:05:45.846687Z","shell.execute_reply":"2024-10-10T13:05:45.845862Z"},"papermill":{"duration":0.015917,"end_time":"2024-10-10T13:05:45.848958","exception":false,"start_time":"2024-10-10T13:05:45.833041","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"When your notebook is run on the hidden test set, inference_server.serve must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first `predict` call, which does not have the usual 1 minute response deadline.","metadata":{"papermill":{"duration":0.00196,"end_time":"2024-10-10T13:05:45.853279","exception":false,"start_time":"2024-10-10T13:05:45.851319","status":"completed"},"tags":[]}},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-10T13:05:45.859184Z","iopub.status.busy":"2024-10-10T13:05:45.858751Z","iopub.status.idle":"2024-10-10T13:05:46.160987Z","shell.execute_reply":"2024-10-10T13:05:46.159859Z"},"papermill":{"duration":0.308219,"end_time":"2024-10-10T13:05:46.163573","exception":false,"start_time":"2024-10-10T13:05:45.855354","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}